---
title: "Logistic Regression Practice"
author: "Nirmal Patel"
output:
  pdf_document: default
  word_document: default
---






# Regression with binary outcomes

```{r setup, include=FALSE}
library(knitr)
library(effects) 
setwd("C:/Users/NP/Desktop/SPRINGBOARD/logistic_regression/dataSets")
```

# Logistic regression

   This far we have used the lm' function to fit our regression models.lm' is great, but limitedâ in particular it only fits models for continuous dependent variables. For categorical dependent variables wecan use the `glm()' function.      

For these models we will use a different dataset, drawn from the National Health Interview Survey. From the [CDC website]:<http://www.cdc.gov/nchs/nhis.htm>

 The National Health Interview Survey (NHIS) has monitored the health of the nation since 1957. NHIS data on a broad range of health topics are collected through personal household interviews. For over 50 years, the U.S. Census Bureau has been the data collection agent for the National Health Interview Survey. Survey results have been instrumental in providing data to track health status, health care access, and progress toward achieving national health objectives.

#  Load the National Health Interview Survey data:
```{r LABS, include=TRUE}
NH11<-readRDS("dataSets/NatHealth2011.rds")
labs <- attributes(NH11)$labels

```

#   [CDC website] <http://www.cdc.gov/nchs/nhis.htm>

# Logistic regression example

  Let's predict the probability of being diagnosed with hypertension   based on age, sex, sleep, and bmi

```{r HYPEV, include=TRUE}
table(NH11$hypev)
str(NH11$hypev) # check stucture of hypev
levels(NH11$hypev) # check levels of hypev
```


 collapse all missing values to NA

```{r NGH11HYPEV, include=TRUE}
NH11$hypev <- factor(NH11$hypev, levels=c("2 No", "1 Yes"))

```
 run our regression model
```{r HYPOUT, include=TRUE}
hyp.out <- glm(hypev~age_p+sex+sleep+bmi,
              data=NH11, family="binomial")
coef(summary(hyp.out))


```


# Logistic regression coefficients

Generalized linear models use link functions, so raw coefficients are difficult to interpret. For example, the age coefficient of .06 in the previous model tells us that for every one unit increase in age, the log odds of hypertension diagnosis increases by 0.06. Since most of us are not used to thinking in log odds this is not too helpful!

One solution is to transform the coefficients to make them easier to   interpret
```{r HYPOUTTRANS, include=TRUE}
hyp.out.tab <- coef(summary(hyp.out))
hyp.out.tab[, "Estimate"] <- exp(coef(hyp.out))
hyp.out.tab

```

# Generating predicted values

   In addition to transforming the log-odds produced by `glm' to odds, we can use the `predict()' function to make direct statements about the predictors in our model. For example, we can ask "How much more likelyis a 63 year old female to have hypertension compared to a 33 year old female?".

 Create a dataset with predictors set at desired levels    
```{r PREDdAT, include=TRUE}
predDat <- with(NH11,
                expand.grid(age_p = c(33, 63),
                            sex = "2 Female",
                            bmi = mean(bmi, na.rm = TRUE),
                            sleep = mean(sleep, na.rm = TRUE)))

```

 predict hypertension at those levels    
```{r PREDdATBI, include=TRUE}
cbind(predDat, predict(hyp.out, type = "response",
                       se.fit = TRUE, interval="confidence",
                       newdata = predDat))

```


  This tells us that a 33 year old female has a 13% probability of having been diagnosed with hypertension, while and 63 year old female has a 48% probability of having been diagnosed.

 Packages for  computing and graphing predicted values

Instead of doing all this ourselves, we can use the effects package to compute quantities of interest for us (cf. the Zelig package).
```{r PLOTHYPOU, include=TRUE}
plot(allEffects(hyp.out))

```


# Exercise: logistic regression

#   Use the NH11 data set that we loaded earlier.

   1. Use glm to conduct a logistic regression to predict ever worked (everwrk) using age (age_p) and marital status (r_maritl).
```{r STRNLEVELS, include=TRUE}
str(NH11$everwrk) # check stucture of everwrk
summary(NH11$everwrk) # check summary of everwrk
levels(NH11$everwrk) # check levels of everwrk

```
```{r STRage, include=TRUE}
str(NH11$age_p) # check stucture of age
```

```{r STRNLEVELmartS, include=TRUE}
levels(NH11$r_maritl) # check levels of r_maritl
summary(NH11$r_maritl) # summary marital status

```


 collapse all missing values to NA
```{r everwrksNH11, include=TRUE}
NH11$everwrk <- factor(NH11$everwrk, levels=c("2 No", "1 Yes"))


```
 run our regression model
```{r everwrks, include=TRUE}
everwrks <- glm(everwrk~age_p+r_maritl,
               data=NH11, family="binomial")
coef(summary(everwrks))



```


#   2. Predict the probability of working for each level of marital status.
```{r MATITLEVEL, include=TRUE}
levels(NH11$r_maritl) # check levels of r_maritl
```



 
gives plots of work and age  and work and marital status
```{r MARITPLOT, include=TRUE}
plot(allEffects(everwrks))

```





